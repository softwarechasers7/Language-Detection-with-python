# -*- coding: utf-8 -*-
"""Language Detection  with ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1liLSu5pgJfy37tkFAfnWkpldq0sL-MM_
"""

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import MultinomialNB
data = pd.read_csv("https://raw.githubusercontent.com/amankharwal/Website-data/master/dataset.csv")
print(data.head())

#Let’s have a look at whether this dataset contains any null values or not:

data.isnull().sum()

#Now let’s have a look at all the languages present in this dataset:

data["language"].value_counts()

#This dataset contains 22 languages with 1000 sentences from each language. This is a very balanced dataset with no missing values, so we can say this dataset is completely ready to be used to train a machine learning model

#Language Detection Model
#Now let’s split the data into training and test sets

x = np.array(data["Text"])
y = np.array(data["language"])

cv = CountVectorizer()
X = cv.fit_transform(x)
X_train, X_test, y_train, y_test = train_test_split(X, y, 
                                                    test_size=0.33, 
                                                    random_state=42)

#As this is a problem of multiclass classification, so I will be using the Multinomial Naïve Bayes algorithm to train the language detection model as this algorithm always performs very well on the problems based on multiclass classification:

model = MultinomialNB()
model.fit(X_train,y_train)
model.score(X_test,y_test)

#Now let’s use this model to detect the language of a text by taking a user input:

user = input("Enter a Text: ")
data = cv.transform([user]).toarray()
output = model.predict(data)
print(output)